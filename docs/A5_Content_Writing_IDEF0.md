# A5 å…§å®¹æ’°å¯«æ¨¡çµ„ IDEF0 è©³ç´°è¨­è¨ˆ

## æ–‡ä»¶è³‡è¨Š
- **æ¨¡çµ„ç·¨è™Ÿ**: A5
- **æ¨¡çµ„åç¨±**: å…§å®¹æ’°å¯«
- **è‹±æ–‡åç¨±**: Content Writing
- **ç‰ˆæœ¬**: v1.0
- **å»ºç«‹æ—¥æœŸ**: 2025-10-30
- **çˆ¶æ¨¡çµ„**: A0 - å°ˆåˆ©æ–‡ä»¶è‡ªå‹•ç”Ÿæˆç³»çµ±

---

## æ¨¡çµ„æ¦‚è¿°

### åŠŸèƒ½æè¿°
å…§å®¹æ’°å¯«æ¨¡çµ„æ˜¯å°ˆåˆ©ç”Ÿæˆçš„æ ¸å¿ƒ,è² è²¬æ ¹æ“šå¤§ç¶±æ’°å¯«æ‘˜è¦ã€æ¬Šåˆ©è¦æ±‚æ›¸å’Œå…·é«”å¯¦æ–½æ–¹å¼,ç¢ºä¿é‚è¼¯é€£è²«ã€è¡“èªä¸€è‡´ã€ç¬¦åˆå°ˆåˆ©æ³•è¦ç¯„ã€‚

### æ ¸å¿ƒè·è²¬
1. **æ‘˜è¦æ’°å¯«**: ç”Ÿæˆ 200-300 å­—çš„æŠ€è¡“æ–¹æ¡ˆæ‘˜è¦
2. **æ¬Šåˆ©è¦æ±‚æ›¸æ’°å¯«**: æ’°å¯«ç¨ç«‹å’Œå¾å±¬æ¬Šåˆ©è¦æ±‚
3. **å…·é«”å¯¦æ–½æ–¹å¼æ’°å¯«**: ç”Ÿæˆ >10000 å­—çš„è©³ç´°èªªæ˜
4. **è¡“èªä¸€è‡´æ€§ç®¡ç†**: ç¢ºä¿å…¨æ–‡è¡“èªçµ±ä¸€

---

## A5-0: æƒ…å¢ƒåœ–

```mermaid
flowchart LR
    A4["A4: å¤§ç¶±ç”Ÿæˆ"]
    A6["A6: åœ–è¡¨ç”Ÿæˆ"]
    A5["å…§å®¹æ’°å¯«<br/>Content Writing"]
    PatentRules["å°ˆåˆ©æ’°å¯«è¦ç¯„"]
    WordCount["å­—æ•¸è¦æ±‚"]
    Terminology["è¡“èªä¸€è‡´æ€§"]
    Abstract["ğŸ“„ abstract.md"]
    Claims["ğŸ“‹ claims.md"]
    Description["ğŸ“– description.md"]
    Terms["ğŸ“š terminology.json"]

    A4 -->|patent_outline.md| A5
    PatentRules -.æ§åˆ¶.-> A5
    WordCount -.æ§åˆ¶.-> A5
    Terminology -.æ§åˆ¶.-> A5

    A5 -->|æ‘˜è¦| Abstract
    A5 -->|æ¬Šåˆ©è¦æ±‚| Claims
    A5 -->|èªªæ˜æ›¸| Description
    A5 -->|è¡“èªè©å…¸| Terms

    Abstract --> A6
    Claims --> A6
    Description --> A6

    style A5 fill:#C8E6C9,stroke:#388E3C,stroke-width:3px
```

---

## A5: é ‚å±¤åŠŸèƒ½åˆ†è§£

```mermaid
flowchart TB
    A51["A5.1<br/>æ‘˜è¦æ’°å¯«<br/>Abstract Writing"]
    A52["A5.2<br/>æ¬Šåˆ©è¦æ±‚æ›¸æ’°å¯«<br/>Claims Writing"]
    A53["A5.3<br/>å…·é«”å¯¦æ–½æ–¹å¼æ’°å¯«<br/>Description Writing"]
    A54["A5.4<br/>è¡“èªä¸€è‡´æ€§ç®¡ç†<br/>Terminology Management"]

    Input["ğŸ“‹ patent_outline.md"] --> A51
    A51 --> AbstractDoc["ğŸ“„ abstract.md"]

    AbstractDoc --> A52
    A52 --> ClaimsDoc["ğŸ“‹ claims.md"]

    ClaimsDoc --> A53
    A53 --> DescDoc["ğŸ“– description.md"]

    A51 -.æå–è¡“èª.-> A54
    A52 -.æå–è¡“èª.-> A54
    A53 -.æå–è¡“èª.-> A54
    A54 --> TermDict["ğŸ“š terminology.json"]

    style A51 fill:#BBDEFB,stroke:#1976D2,stroke-width:2px
    style A52 fill:#BBDEFB,stroke:#1976D2,stroke-width:2px
    style A53 fill:#BBDEFB,stroke:#1976D2,stroke-width:2px
    style A54 fill:#BBDEFB,stroke:#1976D2,stroke-width:2px
```

---

## å­åŠŸèƒ½è©³ç´°è¨­è¨ˆ

### A5.1: æ‘˜è¦æ’°å¯«

#### åŠŸèƒ½æè¿°
æ ¹æ“šå¤§ç¶±çš„ç™¼æ˜å…§å®¹ç« ç¯€,ç”Ÿæˆ 200-300 å­—çš„å°ˆåˆ©æ‘˜è¦,åŒ…å«æŠ€è¡“å•é¡Œã€æŠ€è¡“æ–¹æ¡ˆå’ŒæŠ€è¡“æ•ˆæœã€‚

#### ICOM åˆ†æ

| è¦ç´  | é …ç›® | è©³ç´°èªªæ˜ |
|------|------|----------|
| **Input** | å¤§ç¶±-ç™¼æ˜å…§å®¹ | æŠ€è¡“æ–¹æ¡ˆã€é—œéµç‰¹å¾µã€æœ‰ç›Šæ•ˆæœ |
| **Control** | æ‘˜è¦æ’°å¯«è¦ç¯„ | 200-300 å­—ã€åŒ…å«å•é¡Œ/æ–¹æ¡ˆ/æ•ˆæœ |
| | èªè¨€é¢¨æ ¼ | ç°¡æ½”ã€æº–ç¢ºã€å®¢è§€ |
| **Output** | abstract.md | å®Œæ•´æ‘˜è¦æ–‡æª” |
| **Mechanism** | abstract-writer Agent | å°ˆç”¨æ‘˜è¦æ’°å¯« Agent |
| | Claude AI | æ–‡æœ¬ç”Ÿæˆ |

#### Prompt ç¯„ä¾‹

```python
ABSTRACT_PROMPT = """
è«‹æ ¹æ“šä»¥ä¸‹å°ˆåˆ©å¤§ç¶±æ’°å¯«å°ˆåˆ©æ‘˜è¦:

ç™¼æ˜åç¨±: {title}
æŠ€è¡“é ˜åŸŸ: {technical_field}
æŠ€è¡“å•é¡Œ: {problems}
æŠ€è¡“æ–¹æ¡ˆ: {solution}
æœ‰ç›Šæ•ˆæœ: {advantages}

è¦æ±‚:
1. å­—æ•¸: 200-300 å­—
2. çµæ§‹: æŠ€è¡“å•é¡Œ(1-2å¥) + æŠ€è¡“æ–¹æ¡ˆ(3-4å¥) + æœ‰ç›Šæ•ˆæœ(1-2å¥)
3. èªè¨€: ç°¡æ½”ã€æº–ç¢ºã€å®¢è§€
4. é¿å…: å•†æ¥­å®£å‚³ã€ä¸»è§€è©•åƒ¹

è¼¸å‡ºæ ¼å¼:
æœ¬ç™¼æ˜å…¬é–‹äº†...[æŠ€è¡“æ–¹æ¡ˆæ¦‚è¿°]ã€‚å…·é«”åœ°,...[é—œéµæ­¥é©Ÿ/ç‰¹å¾µ]ã€‚æœ¬ç™¼æ˜çš„æœ‰ç›Šæ•ˆæœåœ¨æ–¼...[ä¸»è¦å„ªé»]ã€‚
"""

async def write_abstract(outline: Dict, claude_client) -> str:
    """æ’°å¯«æ‘˜è¦"""
    prompt = ABSTRACT_PROMPT.format(
        title=outline.get("title", ""),
        technical_field=outline.get("technical_field", ""),
        problems="; ".join(outline.get("background", {}).get("problems", [])),
        solution=outline.get("invention_content", {}).get("technical_solution", ""),
        advantages="; ".join(outline.get("invention_content", {}).get("advantages", []))
    )

    response = await claude_client.messages.create(
        model="claude-3-5-sonnet-20241022",
        max_tokens=1024,
        messages=[{"role": "user", "content": prompt}]
    )

    abstract = response.content[0].text

    # é©—è­‰å­—æ•¸
    word_count = len(abstract)
    if not (200 <= word_count <= 300):
        # é‡æ–°ç”Ÿæˆæˆ–èª¿æ•´
        abstract = adjust_abstract_length(abstract, target=250)

    return abstract
```

---

### A5.2: æ¬Šåˆ©è¦æ±‚æ›¸æ’°å¯«

#### åŠŸèƒ½æè¿°
æ’°å¯«ç¨ç«‹æ¬Šåˆ©è¦æ±‚å’Œå¾å±¬æ¬Šåˆ©è¦æ±‚,ç¢ºä¿ä¿è­·ç¯„åœåˆç†ä¸”å±¤æ¬¡æ¸…æ™°ã€‚

#### ICOM åˆ†æ

| è¦ç´  | é …ç›® | è©³ç´°èªªæ˜ |
|------|------|----------|
| **Input** | å¤§ç¶±-æŠ€è¡“æ–¹æ¡ˆ | é—œéµç‰¹å¾µã€å¯é¸ç‰¹å¾µ |
| | æ‘˜è¦ | abstract.md |
| **Control** | æ¬Šåˆ©è¦æ±‚è¦ç¯„ | ç¨ç«‹+å¾å±¬çµæ§‹ã€å¼•ç”¨é—œä¿‚ |
| | å±¤æ¬¡è¦åŠƒ | 3-4 å€‹ä¿è­·å±¤æ¬¡ |
| **Output** | claims.md | å®Œæ•´æ¬Šåˆ©è¦æ±‚æ›¸ |
| **Mechanism** | claims-writer Agent | å°ˆç”¨æ¬Šåˆ©è¦æ±‚æ’°å¯« Agent |

#### æ¬Šåˆ©è¦æ±‚çµæ§‹

```markdown
# æ¬Šåˆ©è¦æ±‚æ›¸

## ç¨ç«‹æ¬Šåˆ©è¦æ±‚

### æ¬Šåˆ©è¦æ±‚ 1 (æ–¹æ³•)
ä¸€ç¨®[æŠ€è¡“æ–¹æ¡ˆåç¨±],å…¶ç‰¹å¾µåœ¨æ–¼,åŒ…æ‹¬ä»¥ä¸‹æ­¥é©Ÿ:
S1. [æ­¥é©Ÿ1æè¿°];
S2. [æ­¥é©Ÿ2æè¿°];
S3. [æ­¥é©Ÿ3æè¿°];
...

## å¾å±¬æ¬Šåˆ©è¦æ±‚

### æ¬Šåˆ©è¦æ±‚ 2
æ ¹æ“šæ¬Šåˆ©è¦æ±‚1æ‰€è¿°çš„[æŠ€è¡“æ–¹æ¡ˆ],å…¶ç‰¹å¾µåœ¨æ–¼,[å¯é¸ç‰¹å¾µ1]ã€‚

### æ¬Šåˆ©è¦æ±‚ 3
æ ¹æ“šæ¬Šåˆ©è¦æ±‚1æˆ–2æ‰€è¿°çš„[æŠ€è¡“æ–¹æ¡ˆ],å…¶ç‰¹å¾µåœ¨æ–¼,[å¯é¸ç‰¹å¾µ2]ã€‚

...

## ç¨ç«‹æ¬Šåˆ©è¦æ±‚

### æ¬Šåˆ©è¦æ±‚ 11 (ç³»çµ±)
ä¸€ç¨®[æŠ€è¡“æ–¹æ¡ˆåç¨±]çš„ç³»çµ±,å…¶ç‰¹å¾µåœ¨æ–¼,åŒ…æ‹¬:
[æ¨¡çµ„1],ç”¨æ–¼[åŠŸèƒ½1];
[æ¨¡çµ„2],ç”¨æ–¼[åŠŸèƒ½2];
...

### æ¬Šåˆ©è¦æ±‚ 12
æ ¹æ“šæ¬Šåˆ©è¦æ±‚11æ‰€è¿°çš„ç³»çµ±,å…¶ç‰¹å¾µåœ¨æ–¼,[å¯é¸ç‰¹å¾µ]ã€‚
```

#### æ¬Šåˆ©è¦æ±‚æ’°å¯«ç­–ç•¥

```python
async def write_claims(outline: Dict, abstract: str, claude_client) -> str:
    """æ’°å¯«æ¬Šåˆ©è¦æ±‚æ›¸"""

    # 1. æ’°å¯«ç¨ç«‹æ¬Šåˆ©è¦æ±‚1 (æ–¹æ³•)
    method_claim = await write_independent_claim_method(
        outline["invention_content"],
        claude_client
    )

    # 2. æ’°å¯«å¾å±¬æ¬Šåˆ©è¦æ±‚2-10 (æ–¹æ³•çš„å¯é¸ç‰¹å¾µ)
    dependent_claims_method = await write_dependent_claims(
        method_claim,
        outline["invention_content"].get("optional_features", []),
        base_claim_num=1,
        claude_client
    )

    # 3. æ’°å¯«ç¨ç«‹æ¬Šåˆ©è¦æ±‚11 (ç³»çµ±)
    system_claim = await write_independent_claim_system(
        outline["invention_content"],
        claude_client
    )

    # 4. æ’°å¯«å¾å±¬æ¬Šåˆ©è¦æ±‚12-20 (ç³»çµ±çš„å¯é¸ç‰¹å¾µ)
    dependent_claims_system = await write_dependent_claims(
        system_claim,
        outline["invention_content"].get("optional_features", []),
        base_claim_num=11,
        claude_client
    )

    # åˆä½µæ‰€æœ‰æ¬Šåˆ©è¦æ±‚
    all_claims = [
        method_claim,
        *dependent_claims_method,
        system_claim,
        *dependent_claims_system
    ]

    return format_claims_document(all_claims)
```

---

### A5.3: å…·é«”å¯¦æ–½æ–¹å¼æ’°å¯«

#### åŠŸèƒ½æè¿°
æ’°å¯«è©³ç´°çš„å…·é«”å¯¦æ–½æ–¹å¼ç« ç¯€,è¦æ±‚ >10000 å­—,åŒ…å«å¤šå€‹å¯¦æ–½ä¾‹å’Œè©³ç´°çš„æŠ€è¡“ç´°ç¯€ã€‚

#### ICOM åˆ†æ

| è¦ç´  | é …ç›® | è©³ç´°èªªæ˜ |
|------|------|----------|
| **Input** | å¤§ç¶±-å¯¦æ–½æ–¹å¼ | å¯¦æ–½ä¾‹è¦é»åˆ—è¡¨ |
| | æ¬Šåˆ©è¦æ±‚æ›¸ | claims.md |
| **Control** | å­—æ•¸è¦æ±‚ | >10000 å­— |
| | å¯¦æ–½ä¾‹æ•¸é‡ | >= 3 å€‹ |
| | è©³ç´°åº¦è¦æ±‚ | å……åˆ†å…¬é–‹,å¯å¯¦æ–½ |
| **Output** | description.md | å…·é«”å¯¦æ–½æ–¹å¼æ–‡æª” |
| **Mechanism** | description-writer Agent | å°ˆç”¨èªªæ˜æ›¸æ’°å¯« Agent |
| | é•·æ–‡æœ¬ç”Ÿæˆ | Claude é•·ä¸Šä¸‹æ–‡èƒ½åŠ› |

#### æ’°å¯«ç­–ç•¥

```python
async def write_description(
    outline: Dict,
    claims: str,
    claude_client
) -> str:
    """æ’°å¯«å…·é«”å¯¦æ–½æ–¹å¼ (>10000å­—)"""

    sections = []

    # 1. æ•´é«”æ–¹æ¡ˆæè¿° (1000-1500å­—)
    overall_desc = await write_overall_description(
        outline["invention_content"],
        claude_client
    )
    sections.append(overall_desc)

    # 2. å¯¦æ–½ä¾‹1: ä¸»è¦å¯¦æ–½æ–¹å¼ (3000-4000å­—)
    embodiment1 = await write_detailed_embodiment(
        outline["embodiments"][0] if outline.get("embodiments") else {},
        claims,
        is_primary=True,
        claude_client
    )
    sections.append(embodiment1)

    # 3. å¯¦æ–½ä¾‹2: è®ŠåŒ–å¯¦æ–½æ–¹å¼ (2000-3000å­—)
    embodiment2 = await write_detailed_embodiment(
        outline["embodiments"][1] if len(outline.get("embodiments", [])) > 1 else {},
        claims,
        is_primary=False,
        claude_client
    )
    sections.append(embodiment2)

    # 4. å¯¦æ–½ä¾‹3: å¯é¸å¯¦æ–½æ–¹å¼ (2000-3000å­—)
    embodiment3 = await write_detailed_embodiment(
        outline["embodiments"][2] if len(outline.get("embodiments", [])) > 2 else {},
        claims,
        is_primary=False,
        claude_client
    )
    sections.append(embodiment3)

    # 5. æŠ€è¡“ç´°ç¯€è£œå…… (1000-2000å­—)
    technical_details = await write_technical_details(
        outline["invention_content"],
        claude_client
    )
    sections.append(technical_details)

    # åˆä½µæ‰€æœ‰ç« ç¯€
    full_description = "\n\n".join(sections)

    # é©—è­‰å­—æ•¸
    word_count = len(full_description)
    if word_count < 10000:
        # æ“´å±•å…§å®¹
        full_description = await expand_description(
            full_description,
            target_words=10000,
            claude_client
        )

    return full_description

async def write_detailed_embodiment(
    embodiment_outline: Dict,
    claims: str,
    is_primary: bool,
    claude_client
) -> str:
    """æ’°å¯«è©³ç´°å¯¦æ–½ä¾‹"""

    prompt = f"""
è«‹æ’°å¯«å°ˆåˆ©çš„å…·é«”å¯¦æ–½ä¾‹:

å¯¦æ–½ä¾‹è¦é»:
{json.dumps(embodiment_outline, ensure_ascii=False, indent=2)}

æ¬Šåˆ©è¦æ±‚æ›¸:
{claims}

è¦æ±‚:
1. å­—æ•¸: {'' if is_primary else '2000-3000'} å­—
2. çµæ§‹:
   - å¯¦æ–½ä¾‹æ¦‚è¿° (100-200å­—)
   - ç³»çµ±/æ–¹æ³•çµ„æˆ (500-1000å­—)
   - è©³ç´°æ­¥é©Ÿ/æµç¨‹ (1000-2000å­—)
   - å…·é«”åƒæ•¸å’Œé…ç½® (500-1000å­—)
   - å¯¦æ–½æ•ˆæœ (200-300å­—)
3. é¢¨æ ¼: è©³ç´°ã€å…·é«”ã€å¯å¯¦æ–½
4. å¼•ç”¨: å°æ‡‰æ¬Šåˆ©è¦æ±‚çš„ç‰¹å¾µ

è¼¸å‡º Markdown æ ¼å¼ã€‚
"""

    response = await claude_client.messages.create(
        model="claude-3-5-sonnet-20241022",
        max_tokens=8192,
        messages=[{"role": "user", "content": prompt}]
    )

    return response.content[0].text
```

---

### A5.4: è¡“èªä¸€è‡´æ€§ç®¡ç†

#### åŠŸèƒ½æè¿°
å¾æ‰€æœ‰æ’°å¯«çš„å…§å®¹ä¸­æå–è¡“èª,å»ºç«‹è¡“èªè©å…¸,ä¸¦ç¢ºä¿å…¨æ–‡è¡“èªä½¿ç”¨ä¸€è‡´ã€‚

#### ICOM åˆ†æ

| è¦ç´  | é …ç›® | è©³ç´°èªªæ˜ |
|------|------|----------|
| **Input** | abstract.md | æ‘˜è¦æ–‡æª” |
| | claims.md | æ¬Šåˆ©è¦æ±‚æ›¸ |
| | description.md | å…·é«”å¯¦æ–½æ–¹å¼ |
| **Control** | è¡“èªæå–è¦å‰‡ | NERã€é—œéµè©æå– |
| | ä¸€è‡´æ€§è¦å‰‡ | åŒä¸€æ¦‚å¿µä½¿ç”¨åŒä¸€è¡“èª |
| **Output** | terminology.json | è¡“èªè©å…¸ |
| | ä¸€è‡´æ€§å ±å‘Š | ä¸ä¸€è‡´è¡“èªåˆ—è¡¨ |
| **Mechanism** | NLP å·¥å…· | spaCy, NLTK |
| | Claude AI | è¡“èªæ¨™æº–åŒ– |

#### è¡“èªä¸€è‡´æ€§æª¢æŸ¥

```python
def extract_terminology(
    abstract: str,
    claims: str,
    description: str
) -> Dict[str, str]:
    """æå–å…¨æ–‡è¡“èª"""

    all_text = f"{abstract}\n{claims}\n{description}"

    # ä½¿ç”¨ NER æå–å°ˆæ¥­è¡“èª
    terms = extract_technical_terms(all_text)

    # å»ºç«‹è¡“èªè©å…¸
    terminology = {}
    for term in terms:
        if term not in terminology:
            # ç¬¬ä¸€æ¬¡å‡ºç¾çš„å®šç¾©ä½œç‚ºæ¨™æº–
            definition = find_term_definition(term, all_text)
            terminology[term] = definition

    return terminology

def check_terminology_consistency(
    abstract: str,
    claims: str,
    description: str,
    terminology: Dict[str, str]
) -> List[Dict]:
    """æª¢æŸ¥è¡“èªä¸€è‡´æ€§"""

    inconsistencies = []

    for term in terminology.keys():
        # æŸ¥æ‰¾åŒç¾©è©æˆ–è®Šé«”
        variants = find_term_variants(term, [abstract, claims, description])

        if len(variants) > 1:
            inconsistencies.append({
                "standard_term": term,
                "variants": variants,
                "locations": find_term_locations(variants, [abstract, claims, description])
            })

    return inconsistencies

def standardize_terminology(
    content: str,
    terminology: Dict[str, str],
    inconsistencies: List[Dict]
) -> str:
    """æ¨™æº–åŒ–è¡“èª"""

    standardized_content = content

    for issue in inconsistencies:
        standard_term = issue["standard_term"]
        for variant in issue["variants"]:
            if variant != standard_term:
                standardized_content = standardized_content.replace(variant, standard_term)

    return standardized_content
```

---

## Prompt å·¥ç¨‹è¨­è¨ˆ

### æ’°å¯«é¢¨æ ¼ Prompt

```python
WRITING_STYLE_GUIDELINES = """
## å°ˆåˆ©æ’°å¯«é¢¨æ ¼æŒ‡å—

### èªè¨€é¢¨æ ¼
- ä½¿ç”¨ç¬¬ä¸‰äººç¨±,é¿å…ç¬¬ä¸€äººç¨±
- ä½¿ç”¨é™³è¿°å¥,é¿å…ç–‘å•å¥
- ä½¿ç”¨å®¢è§€æè¿°,é¿å…ä¸»è§€è©•åƒ¹
- ä½¿ç”¨å°ˆæ¥­è¡“èª,é¿å…å£èªåŒ–è¡¨é”

### å¥å¼çµæ§‹
- ä½¿ç”¨å®Œæ•´å¥å­,é¿å…ç‰‡æ®µ
- é©ç•¶ä½¿ç”¨é•·å¥,è¡¨é”è¤‡é›œé‚è¼¯
- ä½¿ç”¨ä¸¦åˆ—çµæ§‹,å¢å¼·å¯è®€æ€§
- ä½¿ç”¨æ¨™é»ç¬¦è™Ÿ,æ˜ç¢ºé‚è¼¯é—œä¿‚

### æ®µè½çµ„ç¹”
- æ¯æ®µé›†ä¸­ä¸€å€‹ä¸»é¡Œ
- æ®µè½é–“é‚è¼¯é€£è²«
- ä½¿ç”¨éæ¸¡å¥éŠœæ¥
- é©ç•¶ä½¿ç”¨ç·¨è™Ÿå’Œåˆ—è¡¨

### è¡“èªä½¿ç”¨
- é¦–æ¬¡å‡ºç¾çµ¦å‡ºå®šç¾©
- å…¨æ–‡ä½¿ç”¨çµ±ä¸€è¡“èª
- é¿å…ä½¿ç”¨ç¸®å¯« (é™¤éé€šç”¨)
- ä½¿ç”¨é ˜åŸŸæ¨™æº–è¡“èª

### ç¯„ä¾‹

âŒ éŒ¯èª¤:
æˆ‘å€‘çš„ç³»çµ±å¾ˆå¥½ç”¨,ç”¨æˆ¶éƒ½å¾ˆå–œæ­¡ã€‚å®ƒæ¯”ç¾æœ‰çš„æ–¹æ¡ˆå¿«å¾ˆå¤šã€‚

âœ… æ­£ç¢º:
æœ¬ç™¼æ˜æä¾›çš„ç³»çµ±å…·æœ‰æ“ä½œç°¡ä¾¿ã€æ€§èƒ½å„ªè¶Šçš„ç‰¹é»ã€‚ç›¸æ¯”ç¾æœ‰æŠ€è¡“æ–¹æ¡ˆ,è™•ç†é€Ÿåº¦æå‡ 50% ä»¥ä¸Š,ç”¨æˆ¶æ»¿æ„åº¦é¡¯è‘—æé«˜ã€‚
"""
```

### é•·æ–‡æœ¬ç”Ÿæˆç­–ç•¥

```python
async def generate_long_content(
    outline: str,
    target_words: int,
    claude_client
) -> str:
    """ç”Ÿæˆé•·æ–‡æœ¬ (>10000å­—)"""

    # ç­–ç•¥ 1: åˆ†æ®µç”Ÿæˆ
    sections = split_outline_into_sections(outline)

    generated_sections = []
    for i, section in enumerate(sections):
        section_words = target_words // len(sections)

        prompt = f"""
è«‹æ’°å¯«å°ˆåˆ©èªªæ˜æ›¸çš„ç¬¬ {i+1} éƒ¨åˆ†:

{section}

è¦æ±‚:
- å­—æ•¸: ç´„ {section_words} å­—
- é¢¨æ ¼: è©³ç´°ã€å…·é«”ã€å°ˆæ¥­
- åŒ…å«: æŠ€è¡“ç´°ç¯€ã€åƒæ•¸ã€æ­¥é©Ÿã€ç¤ºä¾‹

{WRITING_STYLE_GUIDELINES}
"""

        response = await claude_client.messages.create(
            model="claude-3-5-sonnet-20241022",
            max_tokens=8192,
            messages=[{"role": "user", "content": prompt}]
        )

        generated_sections.append(response.content[0].text)

    # åˆä½µæ‰€æœ‰æ®µè½
    full_content = "\n\n".join(generated_sections)

    return full_content
```

---

## å“è³ªæ§åˆ¶æ©Ÿåˆ¶

### å“è³ªæª¢æŸ¥æ¸…å–®

```python
QUALITY_CHECKLIST = {
    "abstract": {
        "word_count": (200, 300),
        "structure": ["å•é¡Œ", "æ–¹æ¡ˆ", "æ•ˆæœ"],
        "style": ["å®¢è§€", "ç°¡æ½”"]
    },
    "claims": {
        "independent_claims": (2, 5),
        "dependent_claims": (10, 20),
        "claim_structure": ["å‰åºéƒ¨åˆ†", "ç‰¹å¾µéƒ¨åˆ†"],
        "reference": ["æ­£ç¢ºå¼•ç”¨å‰åºæ¬Šåˆ©è¦æ±‚"]
    },
    "description": {
        "word_count": (10000, float("inf")),
        "embodiments": (3, 10),
        "detail_level": ["å¯å¯¦æ–½", "å……åˆ†å…¬é–‹"],
        "alignment": ["èˆ‡æ¬Šåˆ©è¦æ±‚å°æ‡‰"]
    },
    "terminology": {
        "consistency": 1.0,  # 100% ä¸€è‡´
        "definition": ["é¦–æ¬¡å‡ºç¾çµ¦å‡ºå®šç¾©"],
        "standardization": ["ä½¿ç”¨é ˜åŸŸæ¨™æº–è¡“èª"]
    }
}

def check_content_quality(
    abstract: str,
    claims: str,
    description: str
) -> Dict[str, Dict]:
    """æª¢æŸ¥å…§å®¹è³ªé‡"""

    results = {}

    # 1. æª¢æŸ¥æ‘˜è¦
    results["abstract"] = {
        "word_count": len(abstract),
        "word_count_ok": 200 <= len(abstract) <= 300,
        "has_problem": "å•é¡Œ" in abstract or "ç¼ºé™·" in abstract,
        "has_solution": "æ–¹æ¡ˆ" in abstract or "æ–¹æ³•" in abstract,
        "has_effect": "æ•ˆæœ" in abstract or "å„ªé»" in abstract
    }

    # 2. æª¢æŸ¥æ¬Šåˆ©è¦æ±‚
    claims_list = parse_claims(claims)
    results["claims"] = {
        "total_claims": len(claims_list),
        "independent_claims": count_independent_claims(claims_list),
        "dependent_claims": count_dependent_claims(claims_list),
        "structure_ok": all(check_claim_structure(c) for c in claims_list)
    }

    # 3. æª¢æŸ¥èªªæ˜æ›¸
    results["description"] = {
        "word_count": len(description),
        "word_count_ok": len(description) >= 10000,
        "embodiments": count_embodiments(description),
        "detail_level": assess_detail_level(description),
        "alignment": check_claims_description_alignment(claims, description)
    }

    # 4. æª¢æŸ¥è¡“èªä¸€è‡´æ€§
    terminology = extract_terminology(abstract, claims, description)
    inconsistencies = check_terminology_consistency(abstract, claims, description, terminology)
    results["terminology"] = {
        "total_terms": len(terminology),
        "inconsistencies": len(inconsistencies),
        "consistency_rate": 1 - len(inconsistencies) / max(len(terminology), 1)
    }

    return results
```

---

## å¯¦ä½œå»ºè­°

### æŠ€è¡“é¸å‹

```python
dependencies = [
    "anthropic>=0.18.0",          # Claude AI
    "tiktoken>=0.5.0",            # Token è¨ˆæ•¸
    "spacy>=3.7.0",               # NLP
    "zh-core-web-sm",             # ä¸­æ–‡ NLP æ¨¡å‹
]
```

### ç¨‹å¼ç¢¼çµæ§‹

```
src/
â”œâ”€â”€ writing/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ abstract_writer.py      # A5.1
â”‚   â”œâ”€â”€ claims_writer.py        # A5.2
â”‚   â”œâ”€â”€ description_writer.py   # A5.3
â”‚   â”œâ”€â”€ terminology_manager.py  # A5.4
â”‚   â”œâ”€â”€ prompts.py              # Prompt åº«
â”‚   â”œâ”€â”€ validators.py           # è³ªé‡æª¢æŸ¥
â”‚   â””â”€â”€ utils.py
```

---

## ç¸½çµ

### æ¨¡çµ„ç‰¹é»

âœ… **å°ˆæ¥­æ€§**: ç¬¦åˆå°ˆåˆ©æ³•è¦ç¯„
âœ… **å®Œæ•´æ€§**: æ‘˜è¦+æ¬Šåˆ©è¦æ±‚+èªªæ˜æ›¸
âœ… **è©³ç´°åº¦**: èªªæ˜æ›¸ >10000 å­—
âœ… **ä¸€è‡´æ€§**: å…¨æ–‡è¡“èªçµ±ä¸€

### é—œéµæŒ‡æ¨™

| æŒ‡æ¨™ | ç›®æ¨™å€¼ |
|-----|-------|
| æ‘˜è¦å­—æ•¸ | 200-300 å­— |
| èªªæ˜æ›¸å­—æ•¸ | >10000 å­— |
| æ¬Šåˆ©è¦æ±‚æ•¸ | 15-25 é … |
| è¡“èªä¸€è‡´æ€§ | >95% |
| ç”Ÿæˆæ™‚é–“ | <20 åˆ†é˜ |

---

**æ–‡ä»¶çµæŸ**
